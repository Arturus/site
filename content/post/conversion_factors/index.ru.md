+++
title = "Конверсия и data science III. Как отличить хорошее от плохого?"
subtitle = "Или оценка факторов, влияющих на конверсию"
date = 2019-02-15T00:00:00
tags=['Conversion']
categories=['Internet analytics']
summary = ""
# Optional featured image (relative to `static/img/` folder).
[header]
image = ""
caption = ""

+++
$$\DeclareMathOperator{\E}{E}$$
Как понять, что влияет на конверсию положительно, а что отрицательно?
В принципе в любом отчёте Google Analytics или Я.Метрики есть столбец
"конверсия", и сравнив конверсию в разных строках отчёта, казалось бы,
можно получить исчерпывающий ответ.

Но не надо забывать, что любой отчёт показывает срез данных, сделанный
по *единственному* измерению (источник трафика, география, и т.п.), что
даёт неполную, а иногда даже неверную картину. Рассмотрим простой пример:
есть два города, Москва и Екатеринбург и два вида трафика,
органический и реферальный. Данные по кол-ву визитов и конверсий сведены
в кросс-таблицу в виде `конверсии/визиты = конверсионность`:

<style>th {text-align: center;}</style>

|                 | Referral      | Organic       | Всего (город) |
| --------------- |-------------:|--------------:|--------------:|
| Москва          | $1/100=1.00\%$  | $15/1000=1.50\%$ | $16/1100=\mathbf{1.45}\%$ | 
| Екатеринбург    | $12/1000=1.20\%$| $2/100=2.00\%$   | $14/1100=\mathbf{1.27}\%$ |
| Всего (источник)| $13/1100=1.18\%$| $17/1100=1.54\%$  |               | 

 
 В отчёте по географии будет конверсионность 1.45% для Москвы и
 1.27% для Екатеринбурга (последняя колонка), т.е. трафик из Москвы кажется более
 конверсионным. Но если присмотреться внимательнее, видно, что 
 конверсионность трафика из Москвы на самом деле __меньше__ для
 обоих видов трафика, 1.0% против 1.2% в реферальном трафике и 1.5% против 2.0% 
 в органике! 
  
Причина кажущейся высокой конверсионности Москвы в том, что в ней больше
 больше доля органического трафика, который по своей природе более конверсионный.
То есть, чтобы сделать полноценный вывод о том, что влияет на конверсионность,
анализировать только одно измерение недостаточно. 
 
Теоретически можно построить отчёт одновременно по двум измерениям,
 но во-первых надо ещё догадаться, какие измерения пересекать и на какие цифры обращать внимание, во-вторых 
 в реальной жизни измерений много, десятки, и все они *одновременно* взаимодействуют
 друг с другом. Т.е. на конверсионность влияет одновременно и география, и источник трафика, и
 время суток, и то, с какого устройства
 заходят на сайт, и многое другое. Построить отчёт сразу по десятку измерений и извлечь 
 из него какую либо полезную информацию для обычного человека нереально: слишком много данных. 

Нужны более совершенные способы оценки воздействия различных факторов на конверсию,
 учитывающие совместный вклад всех имеющихся данных. Результатом может быть 
 сводный отчёт/инфографика, присваивающие рейтинг каждому фактору,
 например Екатеринбург даёт +0.3 к конверсии, а реферальное происхождение
 трафика даёт -0.5.  
 
 
## Линейная модель
Самый простой и часто используемый способ решения задач, похожих на нашу - 
использование линейной модели. Дадим каждому фактору 
вес $w_i$, являющийся оценкой влияния фактора. 
Вес положителен, если наличие соответствующего фактора увеличивает вероятность конверсии:
чем больше вес, тем больше увеличивается вероятность. Отрицательные веса
наоборот уменьшают вероятность конверсии.
 
Сумма всех факторов каждого посетителя, умноженных на их веса, даст
значение $z$, называемое также *logits*. Наличие или отсутствие фактора в нашем случае задаются
индикаторными переменными, принимающими значения 1 и 0. Для приведённого 
выше примера было бы четыре фактора и четыре переменных $x_1,\dots,x_4$: `город:Москва`, `город:Екатеринбург`,
`источник:Organic`, `источник:Referral`, плюс одна свободная переменная $b$,
или *bias*, которая будет примерно соответствовать средней конверсии сайта: 
$$z = w_1x_1 + w_2x_2 + w_3x_3 + w_4x_4 + b$$
или в обобщённой векторной записи:
$$z=\mathbf{w}^\top\mathbf{x} + b$$ 

В зависимости от того, что мы хотим в итоге вычислить, 
выбирается link-функция, преобразующая logits в целевую переменную ($y$).
В нашем случае примем за целевую переменную факт наличия конверсии, т.е.
$y=1$, если конверсия случилась, и $y=0$, если не случилась.
В этом случае link-функцией будет [сигмоид](https://ru.wikipedia.org/wiki/%D0%A1%D0%B8%D0%B3%D0%BC%D0%BE%D0%B8%D0%B4%D0%B0):
$$\sigma(z) = \frac{1}{1+e^{-z}}$$
Модель будет выдавать вероятность конверсии для заданного набора факторов ($\mathbf{x}$).
Такой тип модели называется [логистическая регрессия](https://ru.wikipedia.org/wiki/%D0%9B%D0%BE%D0%B3%D0%B8%D1%81%D1%82%D0%B8%D1%87%D0%B5%D1%81%D0%BA%D0%B0%D1%8F_%D1%80%D0%B5%D0%B3%D1%80%D0%B5%D1%81%D1%81%D0%B8%D1%8F):
$$\Pr(y=1|\mathbf{x})=\sigma(\mathbf{w}^{\top}\mathbf{x} + b)$$ 

Далее используется стандартная процедура машинного обучения, подбирающая
такие веса для факторов, которые максимизируют правдоподобие модели.
На деталях обучения не будем останавливаться, интереснее другое -- что получится на реальных сайтах?

## Сайты
Эту и все последующие модели будем тестировать на данных реальных сайтов,
полученных через Logs API Я.Метрики. 
Будем использовать три сайта, дадим им условные названия:
 
* __shop.ml__ -- e-commerce сайт, продающий недорогие товары, в основном хозяйственно-бытового назначения
* __luxshop.ml__ -- тоже e-commerce, с достаточно дорогими товарами, не являющимися предметами первой необходимости
* __courses.ml__ -- сайт с онлайн курсами.

Настоящих адресов раскрывать не буду, т.к. в результатах работы моделей
будут достаточно чувствительные данные. Адреса страниц сайтов и имена рекламных кампаний тоже
изменены, чтобы сайт было невозможно идентифицировать.
 
Для каждого сайта используется выборка данных за один год, в которую
входит от 1 до 10 млн. уникальных посетителей. Число реальных посетителей
в 2-4 раза меньше, из за того, что посетители часто теряют cookies
(чистят, переустанавливают windows, меняют смартфоны, и т.п.)
        

## Оценка качества моделей
Чтобы понять, насколько модель вообще соотносится с реальной жизнью, будем
оценивать её качество по результатам прогноза на тестовой выборке, т.е. на данных, 
которые модель не видела в процессе обучения и настройки параметров. Есть два варианта формирования
тестовой выборки:

1. Равномерный сэмпл, например случайным образом отобранные 10% от всех данных. Это 
традиционный способ, принятый в machine learning.
2. Данные делятся на две части, "прошлое" и "будущее", за будущее принимаются
данные например за последний месяц, за прошлое - всё остальное. "Будущее" 
это тестовая выборка, "прошлое" - обучающая выборка. 

Последний способ
ближе соответствует тому, как модели применяются в реальной жизни, поэтому
его мы и будем использовать. Прогноз из "прошлого" в "будущее" является
более сложным, т.к. здесь проявляется нестационарность: например
рекламные кампании, которые давали хорошую конверсионность в прошлом, 
совсем не обязательно будут так же хорошо работать в будущем. 

Для единообразия, и чтобы модели
были сравнимы друг с другом, будем всегда использовать метрику качества 
[AUC](https://ru.wikipedia.org/wiki/ROC-%D0%BA%D1%80%D0%B8%D0%B2%D0%B0%D1%8F#%D0%9F%D0%BB%D0%BE%D1%89%D0%B0%D0%B4%D1%8C_%D0%BF%D0%BE%D0%B4_%D0%BA%D1%80%D0%B8%D0%B2%D0%BE%D0%B9) (Area Under Curve).

## Структура модели
Вернёмся к нашей модели. Будем прогнозировать конверсии для посетителей,
впервые оказавшихся на сайте, т.е. не имеющих никакой предыдущей истории.
Конверсия должна случиться в рамках первой сессии, т.е. отложенные конверсии
не учитываются. Модель работает со следующими признаками:

* __browser__ -- браузер посетителя
* __device__ -- тип устройства, desktop/smartphone/tablet/tv,
* __advEngine__ -- рекламная система, из которой произошел переход
* __searchEngine__ -- поисковик, из которого произошел переход 
* __socialNetwork__  -- соцсеть, из которой произошёл переход
* __referer__ -- сайт, с которого произошел переход 
* __trafficSource__ -- тип перехода: прямой, organic, реферальный и т.п.
* __mobilePhone__ -- бренд смартфона/планшета
* __networkType__ -- тип сетевого подключения, если известен - ethernet/wifi/etc
* __OS__ -- операционная система посетителя
* __city__ -- город посетителя
* __country__ -- страна посетителя
* __urlDomain__ -- домен из адреса landing page. Смысл в том, что у сайта
может быть несколько доменов, некоторые используются для внутренних нужд,
например тестирования перед выкаткой релиза (test.shop.ml, dev.shop.ml),
и модели надо уметь различать эти домены.
* __landing_l1__ -- первый компонент пути из landing page. Например, для адреса
`http://shop.ml/catalog/electronics/audio/1` это будет `/catalog/`
* __landing_l2__ -- второй компонент пути из landing page. Для адреса
`http://shop.ml/catalog/electronics/audio/1` это будет `/catalog/electronics/` 
* __UTMCampaign__, __UTMMedium__, __UTMSource__, __UTMTerm__ -- UTM тэги, которые 
присутствовали в landing page URL.   
* __openstatService__, __openstatSource__ - OpenStat разметка, автоматически 
проставляется для переходов из Я.Директа.

Все эти признаки являются категорийными, т.е. каждый из них для конкретного
посетителя принимает одно значение из набора возможных, например `city:Moscow`,
`city:Krasnoyarsk`, и т.п. Набор возможных значений ограничен частотой встречаемости:
в него вошли значения, которые встретились не менее чем у 2000 уникальных посетителей.
Все значения ниже этого порога помещены в отдельную категорию `(other)`, 
например `city:(other)`. У признака может не быть явного значения, например
значение `mobilePhone` не определено, если посетитель зашёл на сайт c desktop устройства. 
В этом случае используется специальная категория "значение отсутствует": `mobilePhone:-`.

В качестве потенциальных признаков также рассматривались время дня и день недели, но они не показали
заметного влияния на конверсию, и были исключены из модели, чтобы избежать
переобучения. 

Категорийные признаки переводятся в бинарные (т.е. принимающие значения только 0 или 1)
с помощью one-hot кодирования. Для наших сайтов получается от 500 до 1000 
бинарных признаков.
 
## Линейная модель, результаты
Конверсионность на e-commerce сайтах невысокая, в районе 0.1-0.3%. Т.е.
на 1000 посетителей приходится всего 1-3 конверсии, что делает обучение
модели не совсем тривиальной задачей из за несбалансированности количества
позитивных и негативных примеров. Так, для сайта luxshop.ru в обучающей
выборке всего 2458 позитивных примеров (конверсий), несмотря на казалось
бы большой объем выборки 2.5 млн посетителей. 

Тем не менее, линейная модель вполне работоспособна на таких данных: AUC для сайтов
shop.ml и luxshop.ml находится в районе __76%-78%__. AUC, заметно отличающийся от 50%, говорит о том, что модель
выявила статистические закономерности в данных, поэтому веса факторов, которые
получились в результате обучения, не являются случайными. 

Посмотрим на результаты. Выведем факторы, которые больше всего влияют на 
конверсию, как в положительную так и в отрицательную стороны, для магазина
shop.ml:

{{< figure src="shop_ml_linreg.png" width="527" height="617">}}

Положительные факторы сверху и окрашены красным, отрицательные - снизу и окрашены синим.
Наблюдаемая картина в целом не противоречит здравому смыслу, например для отрицательных факторов:

* OS *Ubuntu* скорее всего используется ботами или для тестирования
* Посетители из *Украины* и *Казахстана*  вряд ли будет делать заказы в магазине, работающем
в другой стране.
* браузер *Opera Mini* уже весьма маргинален, и скорее всего говорит
об использовании устаревшего смартфона и пониженной платежеспособности владельца.  

Но это ещё не окончательная версия. Обратим внимание на фактор `country:Russia`. 
Он имеет солидный положительный вес ~1.4, при этом доля России в трафике
сайта ~95%. C позиции здравого смысла страновые факторы для
остальных 5% трафика должны иметь огромный отрицательный вес (в районе -27), чтобы 
скомпенсировать положительное влияние России. Однако этого не наблюдается, и 
если учесть влияние всех страновых факторов для каждого посетителя из обучающий выборки,
то в среднем получается положительное 
влияние ~1.34. То есть веса, получаемые из линейной модели, 
не гарантируют что сумма факторов для каждой группы признаков (страна, город, и т.п.) будет в среднем нейтральной.
Но это легко исправить, рассчитав для каждого признака поправку (насколько
среднее по всем посетителям влияние факторов по этой переменной отклоняется от нуля),
и скорректировав веса на эту поправку. 
$$\phi\_i=w\_i - \frac{1}{N}\sum\_{k=1}^N\sum\_{j\in G_i} w\_jx\_{k, j}$$

* $\phi_i$ -- фактор для $i$-го признака.
* $w_i$ -- вес из линейной модели для $i$-го признака.
* $N$ -- количество примеров в обучающей выборке.
* $G_i$ -- индексы всех признаков, относящихся к той же группе, что $i$-ый признак, например 
индексы всех страновых признаков. 
* $x\_{k, j}$ -- значение (0 или 1) $j$-го признака для $k$-го
примера из обучающей выборки.
 
Посмотрим, что получилось:

{{< figure src="shop_ml_linreg2.png" width="568" height="617">}}
 
Страновые факторы действительно стали другими, остальные тоже немного скорректировались.
Как и ожидалось, у России
теперь фактор, близкий к нулю, поэтому она не попала в топ, зато в топе
много зарубежных стран с отрицательными факторами, что хорошо соответствует
здравому смыслу.

Самое большое положительное влияние, с большим отрывом -- у белорусского города Могилёв.
Действительно, конверсия трафика из Могилёва целых 3.6%, при средней конверсии
0.38%, и средней конверсии трафика из Беларуси (без Могилёва) 0.31%. Возможно
это аномалия, вызванная неверным определением географического положения (география
 определяется по IP адресам).  

Итак, линейная модель вполне работоспособна. В то же время у неё есть очевидные недостатки,
связанные с её простотой:

1. Линейная модель хорошо работает только для самых простых прогнозов, таких как этот.
Если есть взаимодействие факторов -- например, конверсионность выше у посетителей из Москвы,
но только в том случае, если они заходят со смартфонов, а с десктопных устройств конверсионность
наоборот ниже -- то линейная модель будет неспособна обнаружить такое взаимодействие.
Теоретически можно добавить в модель
синтетические факторы второго и более порядка, т.е. попарные сочетания всех факторов первого уровня, но тогда общее
количество факторов станет огромным, что затруднит интерпретацию модели и усложнит обучение. 

2. Если имеются нелинейные зависимости между фактором и целевой переменной, или факторов между друг другом,
линейная модель будет неспособна с этим работать (что очевидно даже из названия *линейная*). Сейчас
это проблема не проявилась, потому что в модели участвуют только категорийные переменные,
для которых линейности достаточно,
но если добавить в модель, например, время от последней сессии или количество сессий,
то нелинейность очень пригодится.

Учитывая недостатки линейной модели, мы сейчас не будем подробно рассматривать её
работу на других сайтах, вместо этого поищем другое, более универсальное решение.

## Вклады признаков в результат
Долгое время существовал выбор из двух взаимоисключающих вариантов:
 
1. Использовать простую, но при этом интерпретируемую
модель (линейная модель и её разновидности, различные параметрические модели).
В основном такие модели применяются в мире статистики, где традиционно требуется
объяснение полученных результатов.

2. Иметь сложную модель, которая может обучиться потенциально
чему угодно (нейросеть, gradient boosting, SVM, etc), 
но при этом описать в доступных обычному человеку терминах, что 
происходит внутри модели, и как она принимает решения, будет нереально.
Модель будет просто магическим чёрным ящиком, выдающим прогнозы. Такие
модели применяются в мире машинного обучения, там где важен сам
прогноз, а не объяснение, почему он получился именно таким.     

Но существует альтернатива, позволяющая совместить сложность
модели и её интерпретируемость.       

Любые модели, используемые в машинном обучении, можно представить 
как функцию от признаков (features): $f(x_1, x_2, ... x_n)$.
Каждому значению признака $x_i$ можно сопоставить его "вклад" $\phi_i$.
Вклад -- это то, насколько данное значение воздействует на результат работы модели,
отклоняя его от среднестатистического значения. На примере нашей линейной модели:
есть признак `страна`, его значение, отличное от `Россия`, отклоняет
результат в отрицательную сторону (вероятность конверсии уменьшается).
Для признака `город` значение `Могилёв` наоборот отклоняет результат в 
положительную сторону. Сумма вкладов всех признаков для конкретного
примера (в нашем случае для посетителя) равна отклонению результата работы
модели на этом конкретном примере от среднестатистического результата (в нашем
случае от средней конверсионности по всему сайту):

$$\sum\phi_i = f(x) - \E[f(X)] $$
где $x = (x_1,\dots, x_n)$ -- набор признаков одного посетителя, для которого рассчитываются $\phi_i$,
$X$ -- признаки всех посетителей, $\E[\cdot]$ -- матожидание.
 
Естественно, при сложении положительные и отрицательные вклады могут 
полностью или частично нейтрализовать друг друга. Например, вероятность
конверсии посетителя из Литвы (`country:Lithuania`, вклад -1), который
зашёл на сайт со страницы `landing_l2:/proctuct/1H` (вклад +1), будет примерно
равна средней конверсионности по сайту, если не учитывать вклады остальных
признаков. 
  
В линейной модели вклады $\phi_i$ получаются из весов $w_i$ и не зависят 
от конкретного посетителя, например вклад от значения `Могилёв` признака `city`
будет одинаковым для любого посетителя.  Но в более сложных моделях вклад
$\phi_i$ может зависеть от взаимодействий признаков друг с другом, и рассчитывается
индивидуально для каждого примера, другим словами вклад признака `city:Могилёв` может
быть разным для разных посетителей из Могилёва, в зависимости от значений других признаков.

Для линейной модели расчёт вкладов $\phi_i$ очень простой, и мы его уже 
проделали выше. Но как рассчитываются вклады для сложных моделей? 
  
## Вектор Шепли
Решение приходит с довольно неожиданной стороны, из [теории игр](https://ru.wikipedia.org/wiki/%D0%A2%D0%B5%D0%BE%D1%80%D0%B8%D1%8F_%D0%B8%D0%B3%D1%80),
основные положения которой был разработаны в 50-х года прошлого века.
Представим группу игроков, играющих в любую игру с денежным выигрышем,
и кооперирующихся друг с другом (т.е. играющих не друг против друга, а в команде). 
Цель игроков - получение максимального выигрыша. Но вот выигрыш получен,
как справедливо разделить его между игроками? У игроков может быть неодинаковый вклад в игру,
один игрок опытный, и "тянул на себе" всю партию, другой -- новичок, который только учится
играть, и польза от которого вообще сомнительна. Очевидно, нужен
способ для справедливого расчёта *персонального* вклада каждого игрока. 

"Справедливость" можно выразить в более конкретных терминах:

1. Сумма вознаграждений всех игроков равна общему выигрышу (Эффективность)
2. Если два игрока принесли одинаковую пользу, они получают равное вознаграждение, независимо
от того, в составе каких команд они играли. (Симметричность)
3. Если игрок не принёс никакой пользы, его вознаграждение равно нулю. (Аксиома болвана)
4. Если группа игроков играет несколько партий, сумма вознаграждения игрока
равна сумме его вознаграждений в каждой партии. (Аддитивность)

Теория игр постулирует, что единственный способ расчёта, удовлетворяющий
всем четырём условиям, это [вектор Шепли](https://ru.wikipedia.org/wiki/%D0%92%D0%B5%D0%BA%D1%82%D0%BE%D1%80_%D0%A8%D0%B5%D0%BF%D0%BB%D0%B8).
  
{{< figure src="shapely.png" width="622" height="211">}}  
  
Расчёт вектора Шепли можно представить через маржинальные вклады игроков,
когда вклад игрока оценивается по росту выигрыша команды, к которой он присоединился:

* В начале вся команда состоит из игрока **A**. Выигрыш $7, значит и
вклад игрока **A** равен 7.
* Когда к нему присоединяется игрок **C**, выигрыш команды растёт до $15. Значит
вклад игрока **C** равен 8.
* Присоединяется игрок **B**, выигрыш растёт до $19. Вклад игрока **B** равен 
4 единицам, и т.п. 

Но это ещё не полноценный расчёт. Умения игроков могут пересекаться,
например игрок **B** может обладать примерно теми же навыками, что и игрок А.
В одиночку **A** выигрывает $7, а присоединение к нему игрока **B** 
не поднимает выигрыш, т.е. вклад игрока **B** получается нулевым, хотя
**B** в одиночку выигрывает $4.
Получается, что результат зависит от порядка
добавления игроков. Чтобы убрать эту зависимость, надо
учесть все возможные варианты, например для игрока **С**: **C**, **A** + **С**, **AB** + **C**, **B** + **C**
и взять среднее значение вклада. 

Некоторые последовательности будут избыточными, например **AB** + **C** и **BA** + **C**
эквивалентны с точки зрения оценки вклада **С**, поэтому вектор Шэпли
рассчитывают не через последовательности, а на основе множеств,
в которые может войти игрок, такие множества называются *коалиции*. 

Резюмируя всё сказанное выше, получаем определение:
Вектор Шепли (Shapely values) - это распределение выигрышей, 
соответствующее среднему маржинальному вкладу каждого игрока во всех возможных
коалициях с его участием.

Полную формулу расчёта вектора Шэпли не привожу, она довольно громоздкая.
Формула есть в [Википедии](https://en.wikipedia.org/wiki/Shapley_value), или в книге *Interpretable Machine Learning* 
есть [подробная глава](https://christophm.github.io/interpretable-ml-book/shapley.html) о 
применении shapely values для интерпретации моделей.
 
## SHAP 
Вернёмся к машинному обучению. Если рассматривать игру, как
получение моделью результата на основе заданного примера,
а выигрыш, как разницу
между матожиданием результата на всех имеющихся примерах
и результатом, полученном на заданном примере:
$f(x) - \E[f(X)]$ (выигрыш может быть и отрицательным),
то вклады игроков в игру это не что иное, как
вклад $\phi_i$ каждого значения признака в "выигрыш", т.е. насколько сильно
это значение признака повлияло на результат. Концепция
из теории игр оказывается вполне применимой в машинном обучении.

При расчёте вектора Шэпли необходимо формировать коалиции из ограниченного
набора признаков, но далеко не каждая модель позволяет просто взять и убрать признак без 
необходимости заново обучаться с нуля. Потому на практике для формирования
коалиций обычно не убирают "лишние" признаки, а заменяют их на случайные
значения из "фонового" набора данных.
Усреднённый результат модели со случайными значениями признака эквивалентен
результату модели, в которой этот признак вообще отсутствует.

Прямой расчёт вектора Шэпли возможен только 
для совсем маленьких моделей, т.к. число возможных сочетаний (коалиций)
$n$ признаков это $n!$ (факториал). С увеличением количества признаков время 
расчёта растёт экспоненциально и быстро выходит за пределы разумного.
В нашей простой модели всего 21 признак, 21! это уже 51090942171709440000
возможных коалиций. А если учесть, что эти признаки категорийные, и для работы
их надо перевести в бинарное кодирование, то получится около 1000 признаков.
1000! коалиций это число, в котором **2568 цифр**. По этой причине вектора Шепли
долгое время не представляли практического интереса для машинного обучения.

Но недавно были разработаны способы более эффективного расчёта векторов Шэпли
(библиотека [SHAP](https://github.com/slundberg/shap) - SHapely Additive Explanations),
которые используют дополнительную информацию о структуре модели и в результате 
проводят вычисления за вполне приемлемое время. Результаты,
выдаваемые библиотекой, могут быть не совсем "честными" векторами
Шэпли, а их аппроксимацией. Будем называть их SHAP values.
Такие расчёты сейчас лучше всего проработаны
для методов обучения, использующих tree ensembles, например [Gradient Tree Boosting](https://en.wikipedia.org/wiki/Gradient_boosting#Gradient_tree_boosting)
Попробуем рассчитать SHAP values для моделей, обученных с использованием
библиотеки XGBoost.

# XGBoost + SHAP
Новые модели обучены с помощью XGBoost на том же наборе признаков, что и 
линейные модели. В результате получился AUC несколько выше (на 1-2%), чем
у логистической регрессии: XGBoost использует взаимодействие между признаками, которое было 
недоступно для линейных моделей. Возможно, результат
может быть ещё лучше при более тщательной настройке гиперпараметров XGBoost.

Чтобы увидеть факторы, воздействующие на конверсию, рассчитаем 
SHAP values для каждого примера из тестовой выборки.
В отличие от линейной модели, где величина каждого фактора была
константой, SHAP values индивидуальны для каждого примера из выборки, поэтому
на выходе получается не единственное значение для каждого фактора, а распределение.
Таким образом мы получаем ещё и оценку уверенности в степени воздействия фактора. 

## shop.ml
Для визуализации распределений будем использовать [box plot](https://ru.wikipedia.org/wiki/%D0%AF%D1%89%D0%B8%D0%BA_%D1%81_%D1%83%D1%81%D0%B0%D0%BC%D0%B8).
Концы "усов"
соответствуют минимальному и масксимальному значениям SHAP, закрашенный
прямоугольник -- диапазону, в котором сконцентрирована основная 
масса значений. Оранжевая вертикальная линия внутри прямоугольника
соответствует медианному значению.

{{< figure src="shop_ml_shap.png" width="416" height="617">}}

Видно, что в целом результаты похожи
на линейную регрессию: большое положительное влияние оказывают некоторые
landing pages и рефереры, отрицательное влияние -- в основном страны,
отличные от России. Город Могилёв, который был рекордсменом положительного
влияния в линейной модели, тоже имеет положительное влияние, но не такое
экстремальное: среднее всего +0.5, что даже не позволило ему войти в топ 20,
поэтому его нет на диаграмме.

Факторы, рассчитанные на основе SHAP values, более консервативны:
большое положительное или отрицательное влияние приписывается фактору, только
если модель видит достаточно большое количество подтверждающих примеров
в выборке. Это хорошо для анализа воздействия на конверсию,
 т.к. значения конверсионности, рассчитанные на маленькой выборке, 
 ненадёжны (см. [Каким цифррам можно верить?](/post/conversion_numbers/)).

Можно проанализировать и факторы, относящиеся к одному и тому же признаку, 
например по метке UTMSource:
{{< figure src="shop_ml_shap_utmsource.png" width="460" height="372">}}

В этому случае получается некоторый аналог отчёта Я.Метрики или Google Analytics, 
но дающий более внятную картину "что хорошо, а что плохо". Для большинства
меток нет выявленной закономерности по воздействию на конверсионность, поэтому
их медиана находится в околонулевой зоне. В то же время метки, явно 
действующие "в плюс" или "в минус" чётко отделены от основной массы,
это вместо каши из цифр, которая была бы в стандартном отчёте.

## luxshop.ml
{{< figure src="luxshop_ml_shap.png" width="452" height="617">}}
В этом магазине очень сильное влияние у landing страниц, ассоциированных
с корзиной. Похоже, что использовался retargeting: если посетитель оставлял товары
в корзине и уходил без покупки, его "возвращали" в магазин. 
Теоретически, когда такой посетитель вернётся
в магазин, это будет уже повторный визит, и он не должен попасть в выборку.
Но отслеживание посетителей через cookies не на 100% точное, видимо
посетитель успевал потерять или очистить cookies.

Чтобы остальные факторы были более заметны, отобразим ту же диаграмму
без топовых посадочных страниц:
{{< figure src="luxshop_ml_shap_cut.png" width="452" height="617">}}

Можно сделать выводы:

* Очень хорошо по сравнению со всем остальным выглядят прямые заходы (`trafficSource:direct`).
Видимо у магазина работает оффлайн реклама, и/или имеется сильный бренд.
* Трафик из Москвы конвертируется **намного** лучше, чем из остальных городов.
Что не удивительно, учитывая стоимость товаров.
* Заходы с лицевой страницы сайта `landing_l1:/` повышают конверсию.
То есть людям важнее бренд в целом, чем конкретный товар.
* Конверсия ощутимо зависит от типа устройства: desktop устройства `device:desktop`
конвертируются лучше мобильных `device:mobile`. Возможно это связано с тем,
что покупка достаточно дорогих товаров не происходит спонтанно 
(достал в метро смартфон и купил), нужно время на рассматривание и размышления.

Для наглядности, дополнительно выведем факторы только по типу устройства и только по городу:

{{< figure src="luxshop_ml_shap_device.png" width="378" height="114">}}
{{< figure src="luxshop_ml_shap_city.png" width="461" height="604">}}



## Скоринг посетителей
До этого момента мы рассматривали суммарную статистику по факторам для 
всей выборки посетителей. Но не менее интересно увидеть индивидуальные 
факторы для отдельных посетителей. В линейной модели это не имело смысла,
так как факторы для всех одни и те же, но SHAP рассчитывает индивидуальные
факторы на каждый пример (в нашем случае на каждого посетителя). 
Но сначала надо выяснить, в какой шкале вычисляются факторы. Например, фактор, дающий +1, 
это сколько к конверсии?

И линейная модель и большинство других моделей в машинном обучении не
оперируют напрямую вероятностями, выраженными в процентах. Более
удобная для вычислений шкала это log-odds. Если вероятность события это
$p$, то odds, или шансы события, это $p/(1-p)$. В быту шансы записывают
как $x:y$, где $x$ и $y$ соответствуют числителю и знаменателю в выражении,
конвертирующем вероятность в шансы. Например, вероятность 50% это шансы 1:1
$$\frac{0.5}{1-0.5} = \frac{0.5}{0.5} = 1:1$$
вероятность 1% это шансы 1:99
$$\frac{0.01}{1-0.01} = \frac{1}{100-1} = 1:99 $$

log-odds это логарифм шансов, или логистическая функция, давшая название
логистической регрессии, которой мы пользовались в качестве линейной модели:
 
 $$\textit{log-odds}(p) \equiv logit(p)=\log\left(\frac{p}{1-p}\right)$$
 
 Внутри моделей все вычисления происходят в logit шкале (она же log-odds).
 То есть вероятности 50% соответствует значение $\log(0.5/(1-0.5)) = \log(1) = 0$.
 Обычно используется натуральный логарифм, но мы будем использовать логарифм по основанию 2,
 чтобы можно было приблизительно оценивать значения в уме.
 Тогда вероятности 1% соответствует значение 
 $$\log_2\left(\frac{1}{100-1}\right) = \log_2(1/99) = -6.63$$
 а вероятности 99% значение 
 $$\log_2\left(\frac{99}{100-99}\right) = \log_2(99/1) = -6.63$$
 
 
 Векторы Шэпли рассчитываются в этой же шкале, фактор +1 сдвигает
 log-odds на одну единицу. Это означает, что шансы увеличиваются в два раза (т.к. используется основание 2).
 Например, если средняя конверсионность 1%, или 1:99, то фактор +1 даст конверсионность
 2:99 или 1.98%. Можно приблизительно считать
 изменение шансов в $n$ раз эквивалентным изменению конверсионности в $n$ раз, тогда:
 
 $$p\_f = 2^{f}\cdot\E[p] $$
 где $f$ -- значение фактора, $p_f$ -- конверсионность с учётом влияния фактора $f$,
 $\E[p]$ -- средняя конверсионность. Фактор +1 увеличивает конверсионность в два раза,
 фактор -1 соответственно уменьшает в два раза, и т.п.
 
 Теперь собственно скоринг. Будем отображать scorecard каждого посетителя в виде
 столбца, у которого есть:
 
 * Базовое значение (жирная черная горизонтальная линия). Позиция базового значения
  по шкале Y соответствует тому, насколько сдвинута по мнению модели
  вероятность конверсии посетителя относительно матожидания конверсии
  по всем посетителям, т.е "средней" конверсионности. 
 * Положительные факторы (сегменты красного цвета над базовым значением).
  Высота сегмента соответствует вкладу фактора. Чтобы не загромождать
  диаграмму, отображаются только факторы, имеющие вклад больше 0.02.
 * Отрицательные факторы (сегменты синего цвета под базовым значением).

{{< figure src="luxshop_ml_scores.png" width="554" height="467">}}

Сумма положительных и отрицательных факторов равна базовому значению.
Шкала по оси Y -- log-odds. Нулевой уровень шкалы (отмечен пунктиром)
соответствует средней конверсии.

* Посетитель **A** имеет самые высокие шансы сконвертироваться, его базовый
уровень $+3.3$, что соответствует увеличению конверсии в $2^{3.3} \approx 9.85$ раз,
т.е. почти десятикратное увеличение. Это результат удачного сочетания 
факторов: прямой заход, Москва, стационарный компьютер.
* Посетитель **С** наоборот практически лишён положительных факторов, всё
работает против него. Его базовый уровень $-1.3$, это уменьшение
конверсионности в $2^{1.3} \approx 2.46$ раза.   
* Посетители **B** и **D** имеют промежуточную конверсионность, близкую к
средней по сайту.

Scorecards позволяют наглядно увидеть, что модель "думает" о любом
посетителе, а также сравнивать посетителей друг с другом. Они могут быть
быть например хорошим дополнением к информации о посетителе в Я.Метрике.
В простой модели, которой мы сейчас пользуемся, scorecard носит 
скорее разъяснительный характер, т.к. после завершения первого визита всё
равно известно, сконвертировался посетитель или нет. Но потом мы рассмотрим
и более сложные модели, которые предсказывают поведение посетителя в будущем,
и там scorecard станет важным рабочим инструментом.

## courses.ml
Этот сайт не имеет "конверсии" в традиционном понимании, его цель --
сделать так, чтобы посетитель заинтересовался, остался и начал проходить курсы.
Поэтому вместо конверсии будем использовать вероятность того, что
после первого посещения посетитель вернётся на сайт в течение месяца.

Сайт привлекает посетителей в основном через размещение ссылок
на сайтах подходящей тематики, а не через традиционную онлайн рекламу,
поэтому расклад факторов, влияющих на конверсию, здесь сильно отличается
от магазинов:

{{< figure src="courses_ml_shap.png" width="471" height="617">}}

Видно сильное отрицательное влияние служебных доменов: модель поняла,
что посетители, заходящие с этих доменов, ведут себя совсем не так, как остальные.
Чтобы они не мешали анализу, исключим их и построим диаграмму ещё раз:

{{< figure src="courses_ml_shap_cut.png" width="471" height="617">}}

В топе положительных факторов переходы с `coursera.org`, т.к. там есть аудитория,
уже заинтересованная в обучении, а также домен партнёра `partner.courses.ml`,
это white label сервис на отдельном домене. Также
в топе много переходов с почтовых сервисов, т.е. хорошо работает 
привлечение (или возврат) посетителей через рассылки.

В топе отрицательных факторов: 

* `landing_l1:/unsubscribe/` -- отписка от рассылки (неудивительно)
* `browser:—` -- посетители, у которых не определился браузер, вероятно боты.
* `urlDomain:(other)` -- низкочастотные доменные имена, попавшие в группу "остальное", видимо
это тоже служебные домены.
* `referer:lady.mail.ru ` -- переходы с http://lady.mail.ru. На сайте courses.ml курсы в основном IT тематики,
 и к сожалению нет курсов "как найти богатого мужа" или "101 кулинарный
 шедевр с майонезом". Поэтому интерес со стороны аудитории lady.mail.ru
 весьма низок.
 
Scorecards:
{{< figure src="courses_ml_scores.png" width="498" height="684">}}

Посетитель **A** демонстрирует повышение вероятности повторного визита в $2^{3.5} \approx 11.3$
раза по отношению к среднему уровню, посетитель **B** -- понижение в
$2^{4.2} \approx 18.4$ раз, у посетителей **D** и **C** положительные и отрицательные факторы уравновешивают друг друга 
и получаются вероятности, близкие к средним.

# Резюме
Мы научились применять модели машинного обучения для анализа
факторов, влияющих на конверсию. Благодаря применению векторов Шэпли
интерпретация модели любой сложности сводится к линейной комбинации факторов,
которая легко воспринимаются человеком и легко отображается графически (scorecards). 

Пока рассматривались только простые модели, использующие 
исключительно параметры первого перехода на сайт. Более интересны модели, 
работающие с информацией о поведении посетителя на сайте, они позволяют
точнее предсказывать дальнейшие действия посетителя.
Такие продвинутые модели мы рассмотрим в следующих статьях.

Но даже такие довольно простые выводы, которые можно получить на основе
рассмотренных моделей, уже облегчают работу с Интернет-аналитикой. 
Вместо копания в десятках отчётов можно сразу получить готовые ответы --
это и есть результат, к которому надо стремиться.  
        
   

   
 

   

 
 
 
   
  




     
 
 
 
 
  



  
